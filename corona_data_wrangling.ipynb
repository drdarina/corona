{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.dataset_list_files??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "files = api.dataset_download_files('sudalairajkumar/novel-corona-virus-2019-dataset', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download google coordinate file\n",
    "import requests\n",
    "\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.prepared import prep\n",
    "\n",
    "data = requests.get(\"https://raw.githubusercontent.com/datasets/geo-countries/master/data/countries.geojson\").json()\n",
    "\n",
    "# WORLD dataframe uses ISO_A3, so we extract that one from the data\n",
    "iso_a3_lookup = {}\n",
    "for feature in data['features']:\n",
    "    iso_a3_lookup[feature['properties']['ISO_A3']] = prep(shape(feature['geometry']))\n",
    "    \n",
    "def get_iso(point):\n",
    "    for country, geom in iso_a3_lookup.items():\n",
    "        if geom.contains(point):\n",
    "            return country\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, Provinces are not unique.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>ProvinceState</th>\n",
       "      <th>CountryRegion</th>\n",
       "      <th>LastUpdate</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>ULID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2948</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-03-02 15:03:23</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>Guangdong - China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1618</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2020-02-04 00:13:06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toronto, ON - Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>4191</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>Cobb County, GA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-07 16:53:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cobb County, GA - US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>976</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-02-05 21:53:02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Madison, WI - US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>3377</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>Norfolk County, MA</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-03 14:33:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Norfolk County, MA - US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>4492</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>Shelby County, TN</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-08 16:13:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shelby County, TN - US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>5472</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-14 22:33:03</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Texas - US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>5489</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-03-14 12:33:03</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Algeria - Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>1858</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2020-02-08 03:43:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sri Lanka - Sri Lanka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>2143</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>Inner Mongolia</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-02-23 09:43:02</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Inner Mongolia - China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNo ObservationDate       ProvinceState CountryRegion  \\\n",
       "2947  2948      2020-03-02           Guangdong         China   \n",
       "1617  1618      2020-02-16         Toronto, ON        Canada   \n",
       "4190  4191      2020-03-08     Cobb County, GA            US   \n",
       "975    976      2020-02-07         Madison, WI            US   \n",
       "3376  3377      2020-03-04  Norfolk County, MA            US   \n",
       "4491  4492      2020-03-09   Shelby County, TN            US   \n",
       "5471  5472      2020-03-14               Texas            US   \n",
       "5488  5489      2020-03-14             Algeria       Algeria   \n",
       "1857  1858      2020-02-19           Sri Lanka     Sri Lanka   \n",
       "2142  2143      2020-02-23      Inner Mongolia         China   \n",
       "\n",
       "              LastUpdate  Confirmed  Deaths  Recovered  \\\n",
       "2947 2020-03-02 15:03:23     1350.0     7.0     1059.0   \n",
       "1617 2020-02-04 00:13:06        2.0     0.0        0.0   \n",
       "4190 2020-03-07 16:53:03        1.0     0.0        0.0   \n",
       "975  2020-02-05 21:53:02        1.0     0.0        0.0   \n",
       "3376 2020-03-03 14:33:03        1.0     0.0        0.0   \n",
       "4491 2020-03-08 16:13:36        1.0     0.0        0.0   \n",
       "5471 2020-03-14 22:33:03       57.0     0.0        0.0   \n",
       "5488 2020-03-14 12:33:03       37.0     3.0       12.0   \n",
       "1857 2020-02-08 03:43:03        1.0     0.0        1.0   \n",
       "2142 2020-02-23 09:43:02       75.0     0.0       27.0   \n",
       "\n",
       "                         ULID  \n",
       "2947        Guangdong - China  \n",
       "1617     Toronto, ON - Canada  \n",
       "4190     Cobb County, GA - US  \n",
       "975          Madison, WI - US  \n",
       "3376  Norfolk County, MA - US  \n",
       "4491   Shelby County, TN - US  \n",
       "5471               Texas - US  \n",
       "5488        Algeria - Algeria  \n",
       "1857    Sri Lanka - Sri Lanka  \n",
       "2142   Inner Mongolia - China  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('covid_19_data.csv', parse_dates = ['ObservationDate', 'Last Update'])\n",
    "df.columns = [i.replace('/', '').replace(' ', '') for i in df.columns]\n",
    "df.ObservationDate = pd.to_datetime(df.ObservationDate, format='%m/%d/%Y')\n",
    "df.ProvinceState.replace('None', np.nan, inplace=True)\n",
    "df.ProvinceState.fillna(df.CountryRegion, inplace=True)\n",
    "df.ProvinceState = df.ProvinceState.apply(lambda x: x.strip())\n",
    "df.CountryRegion = df.CountryRegion.apply(lambda x: x.strip())\n",
    "\n",
    "# some adjustments to fit with the other datasets\n",
    "df.CountryRegion = df.CountryRegion.apply(lambda x: 'China' if x == 'Mainland China' else x)\n",
    "for col in ['CountryRegion', 'ProvinceState']:\n",
    "    df[col] = df[col].apply(lambda x: 'United Kingdom' if x == 'UK' else x)\n",
    "    df[col] = df[col].apply(lambda x: x.lstrip('(').rstrip(')').rstrip(',').lstrip('\\'').rstrip('\\''))\n",
    "\n",
    "# check if we need a ulid\n",
    "if len(df['ProvinceState'].drop_duplicates()) == len(df[['ProvinceState', 'CountryRegion']].drop_duplicates()):\n",
    "    print('Provinces are unique and can be used as identifier')\n",
    "else:\n",
    "    print('Unfortunately, Provinces are not unique.')\n",
    "    \n",
    "# unique land identifier\n",
    "df['ULID'] = df.ProvinceState + ' - ' + df.CountryRegion\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 5632 rows for 155 countries. Latest data point is from 2020-03-14 00:00:00. Last updated on 2020-03-14 23:53:02\n"
     ]
    }
   ],
   "source": [
    "print('Dataset contains {} rows for {} countries. Latest data point is from {}. Last updated on {}'.format(len(df), df.CountryRegion.nunique(), df.ObservationDate.max(), df.LastUpdate.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this DF rewrites the one above as a time series, but it also contains lat/long data\n",
    "# use it to create a lat/long data lookup\n",
    "df_conf = pd.read_csv('time_series_covid_19_confirmed.csv')\n",
    "df_conf.columns = [i.replace('/', '').replace(' ', '') for i in df_conf.columns]\n",
    "df_conf.ProvinceState.replace('None', np.nan, inplace=True)\n",
    "df_conf.ProvinceState.fillna(df_conf.CountryRegion, inplace=True)\n",
    "df_conf.ProvinceState = df_conf.ProvinceState.apply(lambda x: x.strip())\n",
    "df_conf.CountryRegion = df_conf.CountryRegion.apply(lambda x: x.strip())\n",
    "df_conf['ULID'] = df_conf.ProvinceState + ' - ' + df_conf.CountryRegion\n",
    "from shapely.geometry import Point\n",
    "geometry = [Point(xy) for xy in zip(df_conf['Long'], df_conf['Lat'])]\n",
    "coord_lookup = dict(zip(df_conf.ULID, geometry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the coordinates provided in the dataset to replace place names with ISO names from Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_lookup = {}\n",
    "for name, point in coord_lookup.items():\n",
    "    iso_lookup[name] = get_iso(point)\n",
    "for j in [i for i in df.ULID.unique() if i not in df_conf.ULID.values]:\n",
    "    if j.endswith('US'):\n",
    "        iso_lookup[j] = 'USA'\n",
    "    elif j.endswith('Canada'):\n",
    "        iso_lookup[j] = 'CAN'\n",
    "for k in list(set([i for i in df.ULID if i not in iso_lookup.keys()])):\n",
    "    if 'Diamond Princess' in k:\n",
    "        iso_lookup[k] = ''\n",
    "iso_lookup['Australia - Australia'] = 'AUS'\n",
    "iso_lookup['Ivory Coast - Ivory Coast'] = 'CIV'\n",
    "iso_lookup['Bavaria - Germany'] = 'DEU'\n",
    "iso_lookup['Cruise Ship - Others'] = 'unknown'\n",
    "iso_lookup['From Diamond Princess - Israel'] = 'ISR'\n",
    "iso_lookup['North Ireland - North Ireland'] = 'GBR'\n",
    "iso_lookup['Republic of Ireland - Republic of Ireland'] = 'IRL'\n",
    "iso_lookup['Hong Kong - Hong Kong'] = 'HKG'\n",
    "iso_lookup['Philippines - Philippines'] = 'PHL'\n",
    "iso_lookup['Cruise Ship - Others'] = 'unknown'\n",
    "iso_lookup['New Zealand - New Zealand'] = 'NZL'\n",
    "iso_lookup['Northern Territory - Australia'] = 'AUS'\n",
    "iso_lookup['Faroe Islands - Faroe Islands'] = 'FRO'\n",
    "iso_lookup['Grand Princess Cruise Ship - US'] = 'USA'\n",
    "iso_lookup['Maldives - Maldives'] = 'MDV'\n",
    "iso_lookup['Cyprus - Cyprus'] = 'CYP'\n",
    "iso_lookup['Hong Kong - Hong Kong SAR'] = 'HKG'\n",
    "iso_lookup['Grand Princess - US'] = 'USA'\n",
    "iso_lookup['Hawaii - US'] = 'USA'\n",
    "iso_lookup['Channel Islands - Channel Islands'] = 'GB'\n",
    "iso_lookup['Macau - Macau'] = iso_lookup['Macau - China']\n",
    "iso_lookup['Vatican City - Vatican City'] = 'VAT'\n",
    "iso_lookup['South Korea - South Korea'] = iso_lookup['Korea, South - Korea, South']\n",
    "iso_lookup['Czech Republic - Czech Republic'] = iso_lookup['Czechia - Czechia']\n",
    "iso_lookup['Gibraltar - Gibraltar'] = iso_lookup['Gibraltar - United Kingdom']\n",
    "iso_lookup['Saint Barthelemy - Saint Barthelemy'] = iso_lookup['Saint Barthelemy - France']\n",
    "iso_lookup['St. Martin - St. Martin'] = iso_lookup['St Martin - France']\n",
    "iso_lookup['Palestine - Palestine'] = 'PSE'\n",
    "iso_lookup['Taiwan - Taiwan'] = iso_lookup['Taiwan* - Taiwan*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Congo (Kinshasa - Congo (Kinshasa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-de7311ba51d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iso_a3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mULID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miso_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-de7311ba51d0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iso_a3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mULID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miso_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Congo (Kinshasa - Congo (Kinshasa'"
     ]
    }
   ],
   "source": [
    "df['iso_a3'] = df.ULID.apply(lambda x: iso_lookup[x])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vatican City - Vatican City',\n",
       " 'South Korea - South Korea',\n",
       " 'Czech Republic - Czech Republic',\n",
       " 'Gibraltar - Gibraltar',\n",
       " 'Saint Barthelemy - Saint Barthelemy',\n",
       " 'Congo (Kinshasa - Congo (Kinshasa',\n",
       " 'St. Martin - St. Martin',\n",
       " 'Macau - Macau',\n",
       " 'Palestine - Palestine',\n",
       " 'Taiwan - Taiwan']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in list(set([i for i in df.ULID if i not in iso_lookup.keys()])):\n",
    "    if 'Diamond Princess' in k:\n",
    "        iso_lookup[k] = ''\n",
    "list(set([i for i in df.ULID if i not in iso_lookup.keys()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
